= Running Highly Availiable Hazelcast clusters
:description: High Availability Mode guarantees that even if the Kubernetes node or whole availability zone is down (and all related Hazelcast members are terminated), you will not experience any data loss.

Hazelcast offers the Partition Group Configuration and its types are ZONE_AWARE and NODE_AWARE, which forces Hazelcast members to store the given data partition backup inside a member located in a different availability zone or Kubernetes node. To learn about more, see the xref:hazelcast:clusters:partition-group-configuration.adoc[Platform documentation].

When using the ZONE_AWARE and NODE_AWARE partition grouping, a Hazelcast cluster spanning multiple availability zones and nodes should have an equal number of members in each availability zones and node. Otherwise, it results in uneven partition distribution among the members.

At the Platform Operator, users can configure type of partition-group and required Kubernetes scheduling policy(`topologySpreadConstraints`) to distribute members across availability zones and nodes automatically via modifying single `highAvailabilityMode` parameter.

{description}

== Configuring High Availability Mode 

Below are the configuration options for the High Availability Mode feature.

[cols="20%m,80%a"]
|===
|Field|Description

|`highAvailabilityMode`
|The option to configure type partition-group and Kubernetes scheduling policy:

  - `NODE`: the partition-group is configured as NODE_AWARE and `topologySpreadConstraints` is added into the statefulset:

[source,yaml]
```
      topologySpreadConstraints:
        - maxSkew: 1
          topologyKey: kubernetes.io/hostname
          whenUnsatisfiable: ScheduleAnyway
          labelSelector:
          matchLabels:
            app.kubernetes.io/name: hazelcast
            app.kubernetes.io/instance: hazelcast
            app.kubernetes.io/managed-by: hazelcast-platform-operator
```

  - `ZONE`: the partition-group is configured as ZONE_AWARE and `topologySpreadConstraints` is added into the statefulset: 
[source,yaml]
```
      topologySpreadConstraints:
        - maxSkew: 1
          topologyKey: kubernetes.io/topology.kubernetes.io/zone
          whenUnsatisfiable: ScheduleAnyway
          labelSelector:
          matchLabels:
            app.kubernetes.io/name: hazelcast
            app.kubernetes.io/instance: hazelcast
            app.kubernetes.io/managed-by: hazelcast-platform-operator
```

|===

=== Example Configuration

[source,yaml,subs="attributes+"]
----
include::ROOT:example$/hazelcast-high-availability-mode.yaml[]
----